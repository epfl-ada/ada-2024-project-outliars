{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10041102,"sourceType":"datasetVersion","datasetId":6185467},{"sourceId":10256022,"sourceType":"datasetVersion","datasetId":6344370}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom bs4 import BeautifulSoup\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_article_name(file):\n    return os.path.splitext(file)[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"articles = [extract_article_name(file) for file in os.listdir(\"../input/plaintext-articles\")]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = []\nembeddings = []\n\nfor root, dirs, files in os.walk(\"../input/wikispeedia-htmls\"):\n    if 'index' in dirs:\n        dirs.remove('index')\n    \n    for file in files:\n        if not file.endswith('.htm'):\n            continue\n\n        article_name = extract_article_name(file)\n\n        if article_name not in articles:\n            continue\n        \n        file_path = os.path.join(root, file)\n        \n        with open(file_path, 'r', encoding='utf-8') as f:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n            except UnicodeDecodeError:\n                with open(file_path, 'r', encoding='latin-1') as f:\n                    content = f.read()\n            soup = BeautifulSoup(content, 'lxml')\n            \n            first_paragraph = soup.find('p')\n            text = first_paragraph.get_text(strip=False)\n            \n            embedding = model.encode(text).tolist()\n            embeddings.append(embedding)\n            data.append({\n                \"article_name\": article_name,\n                \"embedding\": embedding,\n            })","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reduced_embeddings = PCA(n_components=192).fit_transform(np.array(embeddings))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for i, reduced_embedding in enumerate(reduced_embeddings):\n#     data[i][\"embedding\"] = reduced_embedding.tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv(\"article_embeddings.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}